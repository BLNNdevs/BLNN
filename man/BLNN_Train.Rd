% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/BLNN_train.R
\name{BLNN_Train}
\alias{BLNN_Train}
\title{Train a BLNN object}
\usage{
BLNN_Train(NET, x, y, iter = 2000, init = NULL, chains = 1,
  seeds = NULL, warmup = floor(iter/2), thin = 1, parallel = FALSE,
  cores = NULL, algorithm = c("NUTS", "HMC", "BFGS"),
  evidence = FALSE, ev.x = NULL, ev.y = NULL, ev.iter = 1,
  control = NULL, display = 0, ...)
}
\arguments{
\item{NET}{the BLNN object which is created using \code{\link{BLNN_Build}}.}

\item{x}{A matrix or data frame of covariates. it is preferred that continuous variables are scaled before training.}

\item{y}{response or target values. A vector for one unit in the output layer, or a matrix/dataframe for more than one unit in the output layer.}

\item{iter}{is the number of samples to draw from the Posterior distribution. In case of "BFGS" algorithm it is the number of iterations.}

\item{init}{A list of vectors containing the initial parameters values or a function. It is strongly recommended to have a different vector for each chain}

\item{chains}{Number of chains to run. Needed for Bayesian training only.}

\item{seeds}{A vector of seeds. One for each chain.}

\item{warmup}{The number of warmup iterations/samples. Default is half the number of iter.}

\item{thin}{The thinning rate to apply to samples}

\item{parallel}{A boolean value to check whether to use Parallel cores or not. Snowfall package is needed if TRUE.}

\item{cores}{Number of cores to be used if parallel is TRUE.}

\item{algorithm}{choose one algorithm from three c("NUTS", "HMC", "BFGS"). NUTS for the NO-U-Turn algorithm, HMC for Hamiltonian Markov chain sampler.
See references below for detailed descriptions of each algorithm. The BFGS for quasi-Newton algorithm.}

\item{evidence}{A boolean value to use the evidence procedure for re-estimating the Hyper-parameters.}

\item{ev.x}{matrix/dataframe of covariates to be used in evidence procedure. Prefered to be historical data or part of the current training data. If left blank while evidence is TRUE, x will be used.}

\item{ev.y}{vector/matrix of targets to be used in evidence procedure. If left blank while evidence is TRUE, y will be used.}

\item{ev.iter}{number of iterations in evidence procedure, see references for more detials. Default is set to 1.}

\item{control}{A list containing several control arguments needed for tunning NUTS and HMC. These arguments are:
\itemize{
\item{adapt_delta: }{ The target acceptance rate. Default is \code{0.8}, for HMC preferred is \code{0.65}.}
\item{momentum.mass: }{ A vector of the momentum variance, default is \code{1}.}
\item{stepsize: }{ The stepsize to be used for NUTS algorithm. If \code{NULL} it will be adapted during warmup.}
\item{useDA: }{ Whether dual averaging for adapting stepsize is used or not. Default is \code{TRUE}.}
\item{gamma: }{ One of DA arguments, double, positive, defaults to \code{2}.}
\item{t0: }{ One of DA arguments, double, positive, defaults to \code{10}.}
\item{kappa: }{ One of DA arguments, double, positive, defaults to \code{0.75}.}
\item{metric: }{ The mass metric to use. Options are: "unit" for a unit diagonal matrix; \code{NULL} to estimate a diagonal matrix during warmup;
a matrix to be used directly (in untransformed space)}
\item{adapt_mass: }{ Whether adaptation of mass matrix is turned
  on. Currently only allowed for diagonal metric.}
\item{w1: }{ integer, positive, defaults to 75.}
\item{w2: }{ integer, positive, defaults to 50.}
\item{w3: }{ integer, positive, defaults to 25.}
In addition one argument used only for NUTS:
\item{max_treedepth: }{ integer, positive, defaults to 10}
For HMC algorithm we can also set:
\item{Lambda: }{ Simulation length of one trajectory, double,\code{[0,1]}}.
}}

\item{display}{Help track the sampler algorithm by displaying several results. Value \code{0} display nothing, \code{1} display the
neural network error after each iteration. \code{2} will display the stepsize and number of leapfrog steps during and after warmup for each iteration.
\code{3} In addition to error function,stepsize, and leapfrog steps it will display the old and new energy for each iteration.}
}
\description{
This function allow the user to train the BLNN object. The user can choose
from three training algorithms. "NUTS" and "HMC" for Bayesian training method, see references for detailed description. The third option is "BFGS" for
quasi-Newton method which is done through optim function.
}
\references{
\itemize{ \item{Neal, R. M. (2011). MCMC using Hamiltonian
  dynamics. Handbook of Markov Chain Monte Carlo.}  \item{Hoffman and
  Gelman (2014). The No-U-Turn sampler: Adaptively setting path lengths
  in Hamiltonian Monte Carlo. J. Mach. Learn. Res.  15:1593-1623.}  }
}
